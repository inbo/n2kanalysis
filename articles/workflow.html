<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Using `n2kanalysis` to analyse monitoring data • n2kanalysis</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Using `n2kanalysis` to analyse monitoring data">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="default" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">n2kanalysis</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.4.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-tutorials" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Tutorials</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-tutorials">
<li><a class="dropdown-item" href="../articles/workflow.html">Using n2kanalysis to analyse monitoring data</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-contributing" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Contributing</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-contributing">
<li><a class="dropdown-item" href="../CONTRIBUTING.html">Contributing</a></li>
    <li><a class="dropdown-item" href="../CODE_OF_CONDUCT.html">Code of conduct</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/inbo/n2kanalysis/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Using `n2kanalysis` to analyse monitoring data</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/inbo/n2kanalysis/blob/main/vignettes/workflow.Rmd" class="external-link"><code>vignettes/workflow.Rmd</code></a></small>
      <div class="d-none name"><code>workflow.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="concept">Concept<a class="anchor" aria-label="anchor" href="#concept"></a>
</h2>
<p>We developed <code>n2kanalysis</code> to analyse data from species
monitoring schemes.</p>
<ol style="list-style-type: decimal">
<li>A first requirement is to make the analysis <strong>reproducible,
traceable and auditable</strong>. Should someone challenge the results
of the analysis, we must be able to demonstrate which analysis was run
with what data.</li>
<li>A second requirement is to make the analysis
<strong>portable</strong>. Portable in the sense that we can move
analyses to other machines to run them. The feature is most relevant
when you have a lot of analyses that take a lot of time.</li>
<li>A third requirement is to make it <strong>as efficient as
possible</strong>. Only run the new analyses. Don’t rerun existing
analyses. Note that any change in data or metadata results in a new
analysis.</li>
</ol>
<p>The <code>n2kanalysis</code> package defines a framework for the
analysis. We recommend to define the actual analysis in a dedicated
package per monitoring scheme. Two examples are
<code>watervogelanalysis::prepare_analysis()</code> and
<code>abvanalysis::prepare_analysis()</code>.</p>
</div>
<div class="section level2">
<h2 id="workflow">Workflow<a class="anchor" aria-label="anchor" href="#workflow"></a>
</h2>
<p>The general workflow within <code>n2kanalysis</code> is as
follows.</p>
<ol style="list-style-type: decimal">
<li>Import the relevant data from the source.</li>
<li>Generate the analysis objects from the imported data.</li>
<li>Fit the analysis objects.</li>
<li>Extract the results from the analysis objects.</li>
</ol>
<div class="section level3">
<h3 id="import-the-relevant-data">Import the relevant data<a class="anchor" aria-label="anchor" href="#import-the-relevant-data"></a>
</h3>
<p>Often the source of the data is not under control of the data
analyst. Hence the data can change in the source during or after the
analysis. Therefore we strongly recommend to import the relevant data
from the source and store it in an “analysis database”. Use only this
database when analysing the data. This offers a stable starting point
for the analysis. In case the source changes, you only need to update
the import script.</p>
<p>The analysis database should be under some kind of version
control.</p>
</div>
<div class="section level3">
<h3 id="generate-the-analysis-objects">Generate the analysis objects<a class="anchor" aria-label="anchor" href="#generate-the-analysis-objects"></a>
</h3>
<p>An <code>n2kModel</code> is a generic S4 class which contains all
required information to fit the model. The machine on which you create
the object needs access to the analysis database. The machine that fit
the model in the objects only needs access to the object itself.
Splitting multiple analyses over different machines is trivial.</p>
</div>
<div class="section level3">
<h3 id="fit-the-models">Fit the models<a class="anchor" aria-label="anchor" href="#fit-the-models"></a>
</h3>
<p>The basic option is to fit the <code>n2kModel</code> object in
memory. A better option is to fit it from the location where you stored
the object. <code><a href="../reference/fit_model.html">fit_model()</a></code> will update the stored object,
making it available for archiving. In case you need to fit several
interdependent objects, you can specify the objects in an
<code>n2kManifest</code> object. Such object lists all
<code>n2kModel</code> objects to fit and the order in which you want to
fit them. The order matters when an <code>n2kModel</code> object depends
on the output of a different <code>n2kModel</code> object.</p>
</div>
<div class="section level3">
<h3 id="extract-the-results">Extract the results<a class="anchor" aria-label="anchor" href="#extract-the-results"></a>
</h3>
<p>The fitted <code>n2kModel</code> contains the model. Hence the user
can extract the required information. <code>n2kanalysis</code> offers a
<code><a href="../reference/get_result.html">get_result()</a></code> function to return all relevant parameters as
a <code>n2kResult</code> object. A <code>n2kResult</code> object
contains both the parameters and the metadata. You can combine multiple
<code>n2kResult</code> objects with <code>combine_result()</code> into a
single <code>n2kResult</code> object and still distinguish the output
from the different analyses. <code><a href="../reference/get_result.html">get_result()</a></code> also return
potential anomalies for <code><a href="../reference/n2k_inla.html">n2k_inla()</a></code> models.</p>
</div>
</div>
<div class="section level2">
<h2 id="traceable-and-auditable">Traceable and auditable<a class="anchor" aria-label="anchor" href="#traceable-and-auditable"></a>
</h2>
<p>Every <code>n2kModel</code> object has a so-called file fingerprint
and status fingerprint.</p>
<p>The file fingerprint is a <a href="https://en.wikipedia.org/wiki/SHA-1" class="external-link">SHA-1 hash</a> based on
everything which will remain stable during the lifetime of the object.
Think of the data, model type, model formula, species group, … Creating
the object generates the hash based on the information at the time of
creation. We check the validity of the file fingerprint before fitting
the model or retrieving results. You can use <code>validObject()</code>
to do the validation manually. The probability that two
<code>n2kModel</code> objects with different stable information get the
same file fingerprint is very small. Therefore we can reference the
<code>n2kModel</code> object by its file fingerprint and use it as the
filename. You can retrieve this hash with
<code><a href="../reference/get_file_fingerprint.html">get_file_fingerprint()</a></code>.</p>
<p>The status fingerprint is based on the file fingerprint and
everything that can change during the lifetime of the object. The most
obvious element is the model. You can retrieve this hash with
<code><a href="../reference/get_status_fingerprint.html">get_status_fingerprint()</a></code>.</p>
<p>Reporting both the file fingerprint and status fingerprint along side
the results uniquely identifies a specific version of the
<code>n2kModel</code> object.</p>
</div>
<div class="section level2">
<h2 id="portable">Portable<a class="anchor" aria-label="anchor" href="#portable"></a>
</h2>
<p>The <code>n2kModel</code> object contains all required information to
fit the model. The only exception is the case where the object needs
information from one or more parent objects. Then you must provide
access to those objects as well.</p>
<p>Use <code><a href="../reference/store_model.html">store_model()</a></code> to store the objects. The
<code>base</code> argument is either the path of a directory on a file
system or an <a href="https://aws.amazon.com/s3/" class="external-link">S3 bucket</a>. The
<code>project</code> argument defines a sub directory at the root of
<code>base</code>. Moving the analyses to a different file system is as
simple as copying everything in the <code>project</code> folder to the
other file system. For S3 buckets you only need to provide the machine
access to the S3 bucket, no need to copy the files manually.
<code><a href="../reference/fit_model.html">fit_model()</a></code> will read the object from the S3 bucket, fit
the model and update the object in the S3 bucket.</p>
</div>
<div class="section level2">
<h2 id="efficient">Efficient<a class="anchor" aria-label="anchor" href="#efficient"></a>
</h2>
<p>We mentioned because that generating the object generates as file
fingerprint which only depends on the stable element. Use
<code>store_model(overwrite = FALSE)</code> when you generate objects.
When nothing changed, the file fingerprint doesn’t change and we keep
the existing object which we might have fit earlier. Suppose you need to
change the definition of some child objects. That will alter the file
fingerprint and thus generate new objects. However the parent objects
remain as is.</p>
<p>Every object has a <code>status</code>. By default
<code><a href="../reference/fit_model.html">fit_model()</a></code> only handles object with status “new” or
“waiting”.</p>
<ol style="list-style-type: decimal">
<li>“new”: the object is ready for fitting. When required, the object
from the parent object is available in the child object.
<code><a href="../reference/fit_model.html">fit_model()</a></code> fits the object.</li>
<li>“waiting”: the object is missing information from at least one
parent object. <code><a href="../reference/fit_model.html">fit_model()</a></code> updates the information of the
parent objects and updates the status accordingly.</li>
<li>“converged”: <code><a href="../reference/fit_model.html">fit_model()</a></code> successfully fitted the
object.</li>
<li>“error”: Something when wrong when fitting the model. Or one of the
parents has the status “error”.</li>
</ol>
<p>Refitting objects with status “error” or “converged” only makes sense
after upgrade <code>n2kanalysis</code>.</p>
</div>
<div class="section level2">
<h2 id="metadata">Metadata<a class="anchor" aria-label="anchor" href="#metadata"></a>
</h2>
<p>Because we need to transfer the <code>n2kModel</code> object between
machines, it is important to add the necessary metadata to the object.
The metadata contains both the file and status fingerprints.</p>
<div class="section level3">
<h3 id="definition-of-the-model">Definition of the model<a class="anchor" aria-label="anchor" href="#definition-of-the-model"></a>
</h3>
<p>The model type is a more generic description of the model, whereas
the formula is the actual formula used for this specific analysis. The
more generic model type allows to group results among species or
location, while the formula still allow to use a different formula for
some objects. Suppose that the generic model uses both year and month a
covariates. When a species is only present during a single month, then
it doesn’t make sense to include month as a covariate for this
species.</p>
<p><code>seed</code> sets the seed to make the analysis
reproducible.</p>
</div>
<div class="section level3">
<h3 id="scheme-species-and-location">Scheme, species and location<a class="anchor" aria-label="anchor" href="#scheme-species-and-location"></a>
</h3>
<p>Other important information in the metadata are the scheme id, the
species group id and the location group id. The scheme id refers to the
monitoring scheme that delivered the data. The species group id refers
to the list of species handled in this analysis. When you analyse a
single species, then you need to create a species group containing only
this species. Similarly, the location group id refers to a list of
locations. The management of the species and location groups is outside
of the scope of <code>n2kanalysis</code>. We recommend three tables:
<code>speciesgroup</code>, <code>species</code> and
<code>speciesgroup_species</code>. <code>speciesgroup</code> and
<code>species</code> should contain at least an <code>id</code> and a
<code>description</code> field. <code>speciesgroup_species</code> should
contain at least a <code>speciesgroup_id</code> and a
<code>species_id</code> field. Hence a species can be part of one or
more species groups. Use a similar structure for
<code>locationgroup</code>, <code>location</code> and
<code>locationgroup_location</code>. <code>result_datasource_id</code>
refers to the database when you store the definitions of
<code>scheme_id</code>, <code>species_group_id</code> and
<code>location_group_id</code>.</p>
</div>
<div class="section level3">
<h3 id="time-stamp">Time-stamp<a class="anchor" aria-label="anchor" href="#time-stamp"></a>
</h3>
<p>Document the available time period with
<code>first_imported_year</code> and <code>last_imported_year</code>.
<code>duration</code> and <code>last_analysed_year</code> refer to the
time span for this analysis. The default <code>duration</code> is the
difference between the last and first imported year. The default
<code>last_analysed_year</code> is the <code>last_imported_year</code>.
Use different values in case the analyse covers only a subset of the
full dataset. Suppose the full dataset spans from 1992 to 2023. If you
want to analyse the period 2011 - 2020, you set
<code>duration = 10</code> and
<code>last_analysed_year = 2020</code>.</p>
<p><code>analysis_date</code> refers to the moment when you imported the
source data. You can use the time-stamp of the commit in case you placed
the data under version control with git.
<code><a href="https://ropensci.github.io/git2rdata/reference/recent_commit.html" class="external-link">git2rdata::recent_commit()</a></code> is a handy function to find the
most recent commit that changed a specific file.</p>
</div>
<div class="section level3">
<h3 id="used-packages">Used packages<a class="anchor" aria-label="anchor" href="#used-packages"></a>
</h3>
<p>The metadata contains one or more “analysis versions”. An “analysis
version” is the list of packages including their version number loading
when creating or fitting the model. Fitting the object on a different
machine with different R packages than the one you generated the object
will result in a second “analysis version”. The goal is to document the
software used during the process.</p>
<p>Store the scripts to generate the objects in a dedicated package.
Load the package when running the script. such a workflow documents the
code to create the objects. Have a look at <a href="https://github.com/inbo/abvanalysis" class="external-link"><code>abvanalysis</code></a>
and <a href="https://github.com/inbo/watervogelanalysis" class="external-link"><code>watervogelanalysis</code></a>
for some real examples. Both packages contain the code to: 1. Import the
data from the source. 1. Create the analysis objects. 1. Get the results
from the analysis objects. 1. Display the results in a report or
website.</p>
</div>
<div class="section level3">
<h3 id="linked-analyses">Linked analyses<a class="anchor" aria-label="anchor" href="#linked-analyses"></a>
</h3>
<p>Optionally you can define one or more parent analyses for the object.
Use this when you need to combine the analyses of different species into
a multi-species index. Or when you want to analyse trends with multiple
imputation. The imputation model is the parent object. The aggregated
imputed data is the child object. The analysis of the aggregated imputed
data is the grandchild object.</p>
</div>
</div>
<div class="section level2">
<h2 id="available-models">Available models<a class="anchor" aria-label="anchor" href="#available-models"></a>
</h2>
<div class="section level3">
<h3 id="n2k_import">
<code>n2k_import()</code><a class="anchor" aria-label="anchor" href="#n2k_import"></a>
</h3>
<p>A dummy model to document the import step. This object allows to use
it a parent object for the subsequent models.</p>
</div>
<div class="section level3">
<h3 id="n2k_inla">
<code>n2k_inla()</code><a class="anchor" aria-label="anchor" href="#n2k_inla"></a>
</h3>
<p>Fits models with integrated nested Laplacian approximation (INLA).
Setting an <code>imputation_size</code> larger than 0 (default) performs
multiple imputation on the missing values using
<code><a href="https://inbo.github.io/multimput/reference/impute.html" class="external-link">multimput::impute()</a></code>.</p>
<p>In case of multiple imputation you can define a <code>minimum</code>
covariate. This covariate hold the minimal value to impute. Use this in
case of incomplete samples. For example when you count the number of
birds in a location and you sampled only a part of the location. The
observed count it thus a lower bound of the true value. Set the response
variable to missing and the minimum variable to the observed count.</p>
<p>Another option is the specify an <code>extra</code> dataset of
observations. We intended this option for rare observations that might
distort the imputation model. For instance due to few observation events
at a location, only a few non-zero observations at a location or a few
extremely high observations at a location. Exclude the observations from
such location for the imputation model and add them to
<code>extra</code>. You won’t get imputations for the missing
observation in <code>extra</code>. But we use the observed numbers in
<code>extra</code> in the subsequent aggregation.</p>
</div>
<div class="section level3">
<h3 id="n2k_inla_comparison">
<code>n2k_inla_comparison()</code><a class="anchor" aria-label="anchor" href="#n2k_inla_comparison"></a>
</h3>
<p>Compares multiple <code><a href="../reference/n2k_inla.html">n2k_inla()</a></code> objects based on the
Wantanabe Akaike Information Criterion (WAIC).</p>
</div>
<div class="section level3">
<h3 id="n2k_composite">
<code>n2k_composite()</code><a class="anchor" aria-label="anchor" href="#n2k_composite"></a>
</h3>
<p>Combines several <code>n2kModel</code> objects into a single
analysis. For example to combine the results of individual species into
a composite species index. The <code>extractor</code> function should
extract the mean and variance of the parameters. The mean is the fitted
object is the mean of the means of every parameters over the models. The
standard error is square root of the average variance of every parameter
over the models. Hence we assume independence of the parameters between
the models.</p>
</div>
<div class="section level3">
<h3 id="n2k_hurdle_imputed">
<code>n2k_hurdle_imputed()</code><a class="anchor" aria-label="anchor" href="#n2k_hurdle_imputed"></a>
</h3>
<p>Combines two <code><a href="../reference/n2k_inla.html">n2k_inla()</a></code> objects with multiple
imputation. The <code>presence</code> model is an
<code><a href="../reference/n2k_inla.html">n2k_inla()</a></code> binomial model that describes the presence of
the species. The <code>count</code> model is an <code><a href="../reference/n2k_inla.html">n2k_inla()</a></code>
zero-truncated Poisson or zero-truncated negative binomial model that
describes the non-zero counts of the species. INLA provides type 0 and
type 1 zero-inflated models. The type 0 model defines the likelihood as
a point mass at 0 and a zero-truncated distribution.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>p</mi><mo>×</mo><msub><mn>1</mn><mrow><mo stretchy="true" form="prefix">[</mo><mi>y</mi><mo>=</mo><mn>0</mn><mo stretchy="true" form="postfix">]</mo></mrow></msub><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>×</mo><mrow><mi>𝒫</mi><mrow><mo stretchy="true" form="prefix" mathvariant="script">(</mo><mi>𝓎</mi><mo stretchy="false" form="prefix" mathvariant="script">|</mo><mi>𝓎</mi><mo mathvariant="script">&gt;</mo><mn mathvariant="script">0</mn><mo stretchy="true" form="postfix" mathvariant="script">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">Prob(y) = p × 1_{[y=0]} + (1 − p) × \mathcal{P(y | y &gt; 0)}</annotation></semantics></math></p>
<p>The type 1 model defines the likelihood as a combination of a point
at zero and a distribution which can produce zero values too.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>p</mi><mo>×</mo><msub><mn>1</mn><mrow><mo stretchy="true" form="prefix">[</mo><mi>y</mi><mo>=</mo><mn>0</mn><mo stretchy="true" form="postfix">]</mo></mrow></msub><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>×</mo><mrow><mi>𝒫</mi><mrow><mo stretchy="true" form="prefix" mathvariant="script">(</mo><mi>𝓎</mi><mo stretchy="true" form="postfix" mathvariant="script">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">Prob(y) = p × 1_{[y=0]} + (1 − p) × \mathcal{P(y)}</annotation></semantics></math></p>
<p>The trick to get a zero-truncated distribution is to use a type 0
zero-inflated distribution and fix the probability of the point mass at
zero to a very small value. Below is the required INLA setting. Note
that the value is expressed on the log scale. <code>-11</code> on the
log scale is equivalent to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>0.0000167</mn></mrow><annotation encoding="application/x-tex">p = 0.0000167</annotation></semantics></math>.</p>
<pre><code><span><span class="va">control.family</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>hyper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>theta2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>initial <span class="op">=</span> <span class="op">-</span><span class="fl">11</span>, fixed <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="n2k_aggregate">
<code>n2k_aggregate()</code><a class="anchor" aria-label="anchor" href="#n2k_aggregate"></a>
</h3>
<p>The aggregation step after multiple imputation.
<code><a href="../reference/fit_model.html">fit_model()</a></code> will call
<code>multimpute::aggregate_impute()</code>. Use the <code>join</code>
argument to select a subset of locations. For example when you ran an
imputation model at the country level and you want to aggregate over a
region within the country. Note that you can use the same impute model
for different aggregation, for example one imputation model at the
country level and aggregations for multiple regions.</p>
</div>
<div class="section level3">
<h3 id="n2k_modelimputed">
<code>n2k_modelimputed()</code><a class="anchor" aria-label="anchor" href="#n2k_modelimputed"></a>
</h3>
<p>Fitting a model an (aggregated) imputed dataset.
<code><a href="../reference/fit_model.html">fit_model()</a></code> will call
<code>multimpute::model_impute()</code>. You can use <code>filter</code>
to subset the data after the imputation. This is a useful feature when
modelling an aggregation on a smaller subset which might result in
leading zero’s in the dataset. You can provide a custom filter function
to remove those observations from the dataset. The function handles
empty datasets after applying the filter.</p>
</div>
</div>
<div class="section level2">
<h2 id="manifest">Manifest<a class="anchor" aria-label="anchor" href="#manifest"></a>
</h2>
<p>The most basic way to fit the models is to loop over all files. This
is suboptimal when some models depend on other models. Since the file
name equals the file fingerprint, the order of the file names has no
link with the optimal order to fit the models.</p>
<p>We solved this problem by introducing the <code><a href="../reference/n2k_manifest.html">n2k_manifest()</a></code>
object. The manifest is simply a dataframe with the file fingerprint of
the model and the file fingerprint of the parent model. This information
is available after generating the models. Hence you can generate all
<code>n2kModel</code> objects and store the link between the objects in
the manifest. When you need multiple parent objects, add one row of
every parent.</p>
<p>Applying <code><a href="../reference/fit_model.html">fit_model()</a></code> on an <code><a href="../reference/n2k_manifest.html">n2k_manifest()</a></code>
fit the models in an optimal order. The initial list of model consist of
the models without parents. Then it handles the children of the initial
models. Then the grandchildren and so on. This order guarantees that all
parent models are fitted before fitting a model.</p>
<p>Another relevant use of a manifest is that is bundles a set of
models. For example all models for a given monitoring scheme in a
specific year. The manifest has is own file fingerprint, useful to
reference a specific manifest.</p>
</div>
<div class="section level2">
<h2 id="docker">Docker<a class="anchor" aria-label="anchor" href="#docker"></a>
</h2>
<p><code>n2kanalysis</code> allows to maximise the reproducibility by
making it easier to run the analysis in a Docker container. Use
<code><a href="../reference/store_manifest_yaml.html">store_manifest_yaml()</a></code> to store the manifest and specify the
Docker image plus optional extra dependencies to install.
<code><a href="../reference/manifest_yaml_to_bash.html">manifest_yaml_to_bash()</a></code> creates a bash script that fits the
models one by one in the specified Docker container.</p>
<p>Using Docker improves the portability of the analysis as well. When
you stored the object in an S3 bucket, you only need to copy the script
to the other machine and run it. Or copy both the script and the objects
in case you store everything on a file system.</p>
<p><code><a href="../reference/manifest_yaml_to_bash.html">manifest_yaml_to_bash()</a></code> offers the option to shut down
the machine at the end of the script. This avoids the cost of running an
idle server. You can also have it to split the analysis over multiple
machines. No fancy parallel computing is involved. Suppose you specified
<code>split = 2</code>. Then you simply get two scripts, one with the
“odd” analyses and one with the “even” analysis.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Thierry Onkelinx, <a href="https://www.vlaanderen.be/inbo/en-gb" class="external-link"><img src="https://inbo.github.io/checklist/reference/figures/logo-en.png" height="24" alt="logo of the Research Institute for Nature and Forest (INBO)"></a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
